{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from pinecone import Pinecone\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.spatial import Voronoi\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(\n",
    "    api_key=os.getenv('PINECONE_API_KEY'),\n",
    "    environment=os.getenv('PINECONE_ENVIRONMENT')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch embeddings from a Pinecone index\n",
    "def fetch_embeddings(index_name, vector_count, dimensions):\n",
    "    index = pc.Index(index_name)\n",
    "    vector_count = index.describe_index_stats()['total_vector_count']\n",
    "    index_arr = index.query(vector=[0 for _ in range(dimensions)], top_k=vector_count, include_metadata=True)\n",
    "\n",
    "    vector_ids = [v['id'] for v in index_arr['matches']]\n",
    "    batch_size = 100  # Adjust batch size as needed\n",
    "    embeddings = []\n",
    "    metadata = []\n",
    "\n",
    "    for i in range(0, len(vector_ids), batch_size):\n",
    "        batch_ids = vector_ids[i:i + batch_size]\n",
    "        response = index.fetch(ids=batch_ids)\n",
    "        batch_embeddings = [v['values'] for v in response['vectors'].values()]\n",
    "        batch_metadata = [v['metadata'] for v in response['vectors'].values()]\n",
    "        for id_, meta in zip(batch_ids, batch_metadata):\n",
    "            meta['id'] = id_\n",
    "        embeddings.extend(batch_embeddings)\n",
    "        metadata.extend(batch_metadata)\n",
    "\n",
    "    return np.array(embeddings), metadata, vector_count\n",
    "\n",
    "# Fetch song embeddings\n",
    "song_embeddings, song_metadata, song_clusters = fetch_embeddings('ast-song-embeddings', 768, 768)\n",
    "print(song_metadata)\n",
    "# Fetch artist embeddings\n",
    "# artist_embeddings, artist_metadata, artist_clusters = fetch_embeddings('artist-embeddings', 768, 768)\n",
    "\n",
    "# Fetch genre embeddings\n",
    "# genre_embeddings, genre_metadata, genre_clusters = fetch_embeddings('genre-embeddings', 768, 768)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit to gmacro on stackoverflow for the foundation for this function\n",
    "def voronoi_finite_polygons_2d(vor, radius=None):\n",
    "    # Check if the input is 2D\n",
    "    if vor.points.shape[1] != 2:\n",
    "        raise ValueError(\"Requires 2D input\")\n",
    "\n",
    "    # Calculate the center of the points\n",
    "    center = vor.points.mean(axis=0)\n",
    "    if radius is None:\n",
    "        radius = vor.points.ptp().max() * 2\n",
    "\n",
    "    new_regions = []\n",
    "    new_vertices = vor.vertices.tolist()\n",
    "\n",
    "    # Construct a map containing all ridges for a given point\n",
    "    all_ridges = construct_ridge_map(vor)\n",
    "\n",
    "    # Reconstruct regions\n",
    "    for p1, region in enumerate(vor.point_region):\n",
    "        vertices = vor.regions[region]\n",
    "\n",
    "        if all(v >= 0 for v in vertices):\n",
    "            # Finite region\n",
    "            new_regions.append(vertices)\n",
    "        else:\n",
    "            # Reconstruct a non-finite region\n",
    "            new_region = reconstruct_infinite_region(p1, vertices, all_ridges, vor, center, radius, new_vertices)\n",
    "            new_regions.append(new_region)\n",
    "\n",
    "    return new_regions, np.asarray(new_vertices)\n",
    "\n",
    "def construct_ridge_map(vor):\n",
    "    all_ridges = {}\n",
    "    for (p1, p2), (v1, v2) in zip(vor.ridge_points, vor.ridge_vertices):\n",
    "        all_ridges.setdefault(p1, []).append((p2, v1, v2))\n",
    "        all_ridges.setdefault(p2, []).append((p1, v1, v2))\n",
    "    return all_ridges\n",
    "\n",
    "def reconstruct_infinite_region(p1, vertices, all_ridges, vor, center, radius, new_vertices):\n",
    "    new_region = [v for v in vertices if v >= 0]\n",
    "    for p2, v1, v2 in all_ridges[p1]:\n",
    "        if v2 < 0:\n",
    "            v1, v2 = v2, v1\n",
    "        if v1 >= 0:\n",
    "            # Finite ridge: already in the region\n",
    "            continue\n",
    "        # Compute the missing endpoint of an infinite ridge\n",
    "        far_point = compute_far_point(p1, p2, v2, vor, center, radius)\n",
    "        new_region.append(len(new_vertices))\n",
    "        new_vertices.append(far_point.tolist())\n",
    "    # Sort region counterclockwise\n",
    "    new_region = sort_region_counterclockwise(new_region, new_vertices)\n",
    "    return new_region\n",
    "\n",
    "def compute_far_point(p1, p2, v2, vor, center, radius):\n",
    "    tangent = vor.points[p2] - vor.points[p1]  # Tangent vector\n",
    "    tangent /= np.linalg.norm(tangent)\n",
    "    normal = np.array([-tangent[1], tangent[0]])  # Normal vector\n",
    "    midpoint = vor.points[[p1, p2]].mean(axis=0)\n",
    "    direction = np.sign(np.dot(midpoint - center, normal)) * normal\n",
    "    far_point = vor.vertices[v2] + direction * radius\n",
    "    return far_point\n",
    "\n",
    "def sort_region_counterclockwise(region, vertices):\n",
    "    vs = np.asarray([vertices[v] for v in region])\n",
    "    center = vs.mean(axis=0)\n",
    "    angles = np.arctan2(vs[:, 1] - center[1], vs[:, 0] - center[0])\n",
    "    sorted_region = np.array(region)[np.argsort(angles)]\n",
    "    return sorted_region.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "song_reduced_embeddings = pca.fit_transform(song_embeddings)\n",
    "# Perform K-means clustering\n",
    "n_clusters = song_clusters // 10  # Adjust this number as needed\n",
    "kmeans = KMeans(n_clusters=n_clusters, init=\"k-means++\", n_init=4, random_state=42)\n",
    "song_cluster_labels = kmeans.fit_predict(song_reduced_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'x': song_reduced_embeddings[:, 0],\n",
    "    'y': song_reduced_embeddings[:, 1],\n",
    "    'name': [m['name'] for m in song_metadata],\n",
    "    'artist': [m['artist'] for m in song_metadata],\n",
    "    'genre': [m['genre'] for m in song_metadata],\n",
    "    'cluster': song_cluster_labels,\n",
    "    'id': [m['id'] for m in song_metadata]\n",
    "}\n",
    "\n",
    "# Create a DataFrame for easier manipulation\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "vor = Voronoi(kmeans.cluster_centers_)\n",
    "regions, vertices = voronoi_finite_polygons_2d(vor)\n",
    "\n",
    "# Generate a unique color for each region\n",
    "def generate_color(name, factor=0.25):\n",
    "    \"\"\"Generate a pastel color for the given name.\"\"\"\n",
    "    # Generate a color based on the hash of the name\n",
    "    hash_object = hashlib.md5(name.encode())\n",
    "    hex_dig = hash_object.hexdigest()\n",
    "    base_color = [int(hex_dig[i:i+2], 16) for i in (0, 2, 4)]\n",
    "\n",
    "    # Mix the color with white\n",
    "    pastel_color = [(1 - factor) * c + factor * 255 for c in base_color]\n",
    "    pastel_color_hex = ''.join(f'{int(c):02x}' for c in pastel_color)\n",
    "\n",
    "    return '#' + pastel_color_hex\n",
    "\n",
    "# Create Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add Voronoi regions, each with a different color\n",
    "for region, center in zip(regions, kmeans.cluster_centers_):\n",
    "    polygon = vertices[region]\n",
    "    color = generate_color(str(center))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=polygon[:, 0],\n",
    "        y=polygon[:, 1],\n",
    "        fill=\"toself\",\n",
    "        fillcolor=color,\n",
    "        mode='lines',\n",
    "        line=dict(color='rgba(0,0,0,0)')  # No border color\n",
    "    ))\n",
    "\n",
    "# Add centroids\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=kmeans.cluster_centers_[:, 0],\n",
    "    y=kmeans.cluster_centers_[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=10, color='white', symbol='x'),\n",
    "    name='Centroids'\n",
    "))\n",
    "\n",
    "# Add scatter plot of points\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df['x'],\n",
    "    y=df['y'],\n",
    "    mode='markers',\n",
    "    marker=dict(color='black', size=5),\n",
    "    text=df.apply(lambda row: f\"{row['name']} by {row['artist']}\", axis=1),\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"K-means clustering on Spotify embeddings (PCA-reduced)\",\n",
    "    xaxis=dict(visible=False),\n",
    "    yaxis=dict(visible=False),\n",
    "    showlegend=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    "    plot_bgcolor='rgba(0,0,0,0)'\n",
    ")\n",
    "\n",
    "fig.update_xaxes(minallowed=df['x'].min()-1, maxallowed=df['x'].max()+1)\n",
    "fig.update_yaxes(minallowed=df['y'].min()-1, maxallowed=df['y'].max()+1)\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pinecone\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = pinecone.Pinecone(\n",
    "    api_key=os.getenv('PINECONE_API_KEY'),\n",
    "    environment=os.getenv('PINECONE_ENVIRONMENT')\n",
    ")\n",
    "\n",
    "# Connect to the Pinecone index\n",
    "index = pc.Index('ast-song-embeddings')\n",
    "\n",
    "# Load artist metadata\n",
    "with open('./metadata/artist_metadata.json') as f:\n",
    "    artist_metadata = json.load(f)\n",
    "\n",
    "print(artist_metadata)\n",
    "# Function to fetch embeddings from Pinecone based on song IDs\n",
    "def fetch_embeddings_by_ids(index, song_ids):\n",
    "    embeddings = {}\n",
    "    batch_size = 100  # Adjust batch size as needed\n",
    "    for i in range(0, len(song_ids), batch_size):\n",
    "        batch_ids = song_ids[i:i + batch_size]\n",
    "        response = index.fetch(ids=batch_ids)\n",
    "        for song_id, vector_data in response['vectors'].items():\n",
    "            embeddings[song_id] = vector_data['values']\n",
    "    return embeddings\n",
    "\n",
    "# Get all song IDs from the artist metadata\n",
    "all_song_ids = [song['id'] for songs in artist_metadata.values() for song in songs]\n",
    "\n",
    "# Fetch embeddings for all song IDs\n",
    "song_embeddings_dict = fetch_embeddings_by_ids(index, all_song_ids)\n",
    "\n",
    "# Debugging: Print some IDs to verify\n",
    "#print(\"Fetched song IDs from Pinecone index:\", list(song_embeddings_dict.keys())[:10])\n",
    "\n",
    "# Calculate average embeddings for each artist\n",
    "artist_embeddings = {}\n",
    "for artist, songs in artist_metadata.items():\n",
    "    embeddings = []\n",
    "    for song in songs:\n",
    "        song_id = song['id']\n",
    "        if song_id in song_embeddings_dict:\n",
    "            embeddings.append(song_embeddings_dict[song_id])\n",
    "        else:\n",
    "            print(f\"Song ID {song_id} not found in Pinecone index\")\n",
    "    if embeddings:\n",
    "        artist_embeddings[artist] = np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        print(f\"No embeddings found for artist {artist}\")\n",
    "\n",
    "# Convert artist embeddings to a list of tuples (artist, embedding)\n",
    "artist_embeddings_list = [(artist, embedding) for artist, embedding in artist_embeddings.items()]\n",
    "\n",
    "# Check if the list is not empty\n",
    "if not artist_embeddings_list:\n",
    "    raise ValueError(\"No artist embeddings found.\")\n",
    "\n",
    "# Separate artist names and embeddings\n",
    "artist_names, embeddings = zip(*artist_embeddings_list)\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "# edit artist metadata here\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "artist_reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "# Perform K-means clustering\n",
    "n_clusters = max(1, len(artist_names) // 10)  # Ensure at least 1 cluster\n",
    "kmeans = KMeans(n_clusters=n_clusters, init=\"k-means++\", n_init=4, random_state=42)\n",
    "artist_cluster_labels = kmeans.fit_predict(artist_reduced_embeddings)\n",
    "\n",
    "# If everything works fine, print success message\n",
    "print(\"PCA and K-means clustering completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for easier manipulation\n",
    "data = {\n",
    "    'x': artist_reduced_embeddings[:, 0],\n",
    "    'y': artist_reduced_embeddings[:, 1],\n",
    "    'name': artist_names,\n",
    "    'cluster': artist_cluster_labels,\n",
    "    'id': [artist for artist in artist_names]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Voronoi diagram\n",
    "vor = Voronoi(kmeans.cluster_centers_)\n",
    "regions, vertices = voronoi_finite_polygons_2d(vor)\n",
    "\n",
    "# Generate a unique color for each region\n",
    "def generate_color(name, factor=0.25):\n",
    "    \"\"\"Generate a pastel color for the given name.\"\"\"\n",
    "    # Generate a color based on the hash of the name\n",
    "    hash_object = hashlib.md5(name.encode())\n",
    "    hex_dig = hash_object.hexdigest()\n",
    "    base_color = [int(hex_dig[i:i+2], 16) for i in (0, 2, 4)]\n",
    "\n",
    "    # Mix the color with white\n",
    "    pastel_color = [(1 - factor) * c + factor * 255 for c in base_color]\n",
    "    pastel_color_hex = ''.join(f'{int(c):02x}' for c in pastel_color)\n",
    "\n",
    "    return '#' + pastel_color_hex\n",
    "\n",
    "# Create Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add Voronoi regions, each with a different color\n",
    "for region, center in zip(regions, kmeans.cluster_centers_):\n",
    "    polygon = vertices[region]\n",
    "    color = generate_color(str(center))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=polygon[:, 0],\n",
    "        y=polygon[:, 1],\n",
    "        fill=\"toself\",\n",
    "        fillcolor=color,\n",
    "        mode='lines',\n",
    "        line=dict(color='rgba(0,0,0,0)')  # No border color\n",
    "    ))\n",
    "\n",
    "# Add centroids\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=kmeans.cluster_centers_[:, 0],\n",
    "    y=kmeans.cluster_centers_[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=10, color='white', symbol='x'),\n",
    "    name='Centroids'\n",
    "))\n",
    "\n",
    "# Add scatter plot of points\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df['x'],\n",
    "    y=df['y'],\n",
    "    mode='markers',\n",
    "    marker=dict(color='black', size=5),\n",
    "    text=df.apply(lambda row: f\"{row['name']}\", axis=1),\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"K-means clustering on Spotify embeddings (PCA-reduced)\",\n",
    "    xaxis=dict(visible=False),\n",
    "    yaxis=dict(visible=False),\n",
    "    showlegend=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    "    plot_bgcolor='rgba(0,0,0,0)'\n",
    ")\n",
    "\n",
    "fig.update_xaxes(minallowed=df['x'].min()-1, maxallowed=df['x'].max()+1)\n",
    "fig.update_yaxes(minallowed=df['y'].min()-1, maxallowed=df['y'].max()+1)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pinecone\n",
    "import pandas as pd\n",
    "from scipy.spatial import Voronoi\n",
    "import hashlib\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = pinecone.Pinecone(\n",
    "    api_key=os.getenv('PINECONE_API_KEY'),\n",
    "    environment=os.getenv('PINECONE_ENVIRONMENT')\n",
    ")\n",
    "\n",
    "# Connect to the Pinecone index\n",
    "index = pc.Index('ast-song-embeddings')\n",
    "\n",
    "# Load genre metadata\n",
    "with open('./metadata/genres_metadata.json') as f:\n",
    "    genre_metadata = json.load(f)\n",
    "\n",
    "# Function to fetch embeddings from Pinecone based on song IDs\n",
    "def fetch_embeddings_by_ids(index, song_ids):\n",
    "    embeddings = {}\n",
    "    batch_size = 100  # Adjust batch size as needed\n",
    "    for i in range(0, len(song_ids), batch_size):\n",
    "        batch_ids = song_ids[i:i + batch_size]\n",
    "        response = index.fetch(ids=batch_ids)\n",
    "        for song_id, vector_data in response['vectors'].items():\n",
    "            embeddings[song_id] = vector_data['values']\n",
    "    return embeddings\n",
    "\n",
    "# Get all song IDs from the genre metadata\n",
    "all_song_ids = [song['id'] for songs in genre_metadata.values() for song in songs]\n",
    "\n",
    "# Fetch embeddings for all song IDs\n",
    "song_embeddings_dict = fetch_embeddings_by_ids(index, all_song_ids)\n",
    "\n",
    "# Debugging: Print some IDs to verify\n",
    "#print(\"Fetched song IDs from Pinecone index:\", list(song_embeddings_dict.keys())[:10])\n",
    "\n",
    "# Calculate average embeddings for each genre\n",
    "genre_embeddings = {}\n",
    "for genre, songs in genre_metadata.items():\n",
    "    embeddings = []\n",
    "    for song in songs:\n",
    "        song_id = song['id']\n",
    "        if song_id in song_embeddings_dict:\n",
    "            embeddings.append(song_embeddings_dict[song_id])\n",
    "        else:\n",
    "            print(f\"Song ID {song_id} not found in Pinecone index\")\n",
    "    if embeddings:\n",
    "        genre_embeddings[genre] = np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        print(f\"No embeddings found for genre {genre}\")\n",
    "\n",
    "# Convert genre embeddings to a list of tuples (genre, embedding)\n",
    "genre_embeddings_list = [(genre, embedding) for genre, embedding in genre_embeddings.items()]\n",
    "\n",
    "# Check if the list is not empty\n",
    "if not genre_embeddings_list:\n",
    "    raise ValueError(\"No genre embeddings found.\")\n",
    "\n",
    "# Separate genre names and embeddings\n",
    "genre_names, embeddings = zip(*genre_embeddings_list)\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "genre_reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "# Perform K-means clustering\n",
    "n_clusters = max(1, len(genre_names) // 5)  # Ensure at least 1 cluster\n",
    "kmeans = KMeans(n_clusters=n_clusters, init=\"k-means++\", n_init=4, random_state=42)\n",
    "genre_cluster_labels = kmeans.fit_predict(genre_reduced_embeddings)\n",
    "\n",
    "# If everything works fine, print success message\n",
    "print(\"PCA and K-means clustering completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for easier manipulation\n",
    "data = {\n",
    "    'x': genre_reduced_embeddings[:, 0],\n",
    "    'y': genre_reduced_embeddings[:, 1],\n",
    "    'name': genre_names,\n",
    "    'cluster': genre_cluster_labels,\n",
    "    'id': [genre for genre in genre_names]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Voronoi diagram\n",
    "vor = Voronoi(kmeans.cluster_centers_)\n",
    "regions, vertices = voronoi_finite_polygons_2d(vor)\n",
    "\n",
    "# Generate a unique color for each region\n",
    "def generate_color(name, factor=0.25):\n",
    "    \"\"\"Generate a pastel color for the given name.\"\"\"\n",
    "    # Generate a color based on the hash of the name\n",
    "    hash_object = hashlib.md5(name.encode())\n",
    "    hex_dig = hash_object.hexdigest()\n",
    "    base_color = [int(hex_dig[i:i+2], 16) for i in (0, 2, 4)]\n",
    "\n",
    "    # Mix the color with white\n",
    "    pastel_color = [(1 - factor) * c + factor * 255 for c in base_color]\n",
    "    pastel_color_hex = ''.join(f'{int(c):02x}' for c in pastel_color)\n",
    "\n",
    "    return '#' + pastel_color_hex\n",
    "\n",
    "# Create Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add Voronoi regions, each with a different color\n",
    "for region, center in zip(regions, kmeans.cluster_centers_):\n",
    "    polygon = vertices[region]\n",
    "    color = generate_color(str(center))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=polygon[:, 0],\n",
    "        y=polygon[:, 1],\n",
    "        fill=\"toself\",\n",
    "        fillcolor=color,\n",
    "        mode='lines',\n",
    "        line=dict(color='rgba(0,0,0,0)')  # No border color\n",
    "    ))\n",
    "\n",
    "# Add centroids\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=kmeans.cluster_centers_[:, 0],\n",
    "    y=kmeans.cluster_centers_[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=10, color='white', symbol='x'),\n",
    "    name='Centroids'\n",
    "))\n",
    "\n",
    "# Add scatter plot of points\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df['x'],\n",
    "    y=df['y'],\n",
    "    mode='markers',\n",
    "    marker=dict(color='black', size=5),\n",
    "    text=df.apply(lambda row: f\"{row['name']}\", axis=1),\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"K-means clustering on Spotify genre embeddings (PCA-reduced)\",\n",
    "    xaxis=dict(visible=False),\n",
    "    yaxis=dict(visible=False),\n",
    "    showlegend=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    "    plot_bgcolor='rgba(0,0,0,0)'\n",
    ")\n",
    "\n",
    "fig.update_xaxes(minallowed=df['x'].min()-1, maxallowed=df['x'].max()+1)\n",
    "fig.update_yaxes(minallowed=df['y'].min()-1, maxallowed=df['y'].max()+1)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
